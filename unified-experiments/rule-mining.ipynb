{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Rule Induction Notebook\n",
    "\n",
    "Continuoulsy refined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%store -z acc_list \n",
    "#%store -z prec_list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## README\n",
    "\n",
    "- GLRM needs to run in proper (conda) aix360 environment\n",
    "- BRCG runs with proper (conda) aix360 environment\n",
    "- Use aix360i environment for RIPPER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceed with configuration: miniloan\n"
     ]
    }
   ],
   "source": [
    "from config import config_dict\n",
    "from config import config_dict_imbalanced\n",
    "\n",
    "# document config order\n",
    "CONFIG = config_dict_imbalanced[\"CONFIG-I4\"]\n",
    "print('Proceed with configuration:', CONFIG[\"NAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing dev version v0.982 of RIPPER\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# import os\n",
    "from sklearn.model_selection import train_test_split #, GridSearchCV\n",
    "from sklearn.metrics import matthews_corrcoef,fbeta_score,confusion_matrix,f1_score,precision_score, recall_score, accuracy_score, balanced_accuracy_score, confusion_matrix, r2_score, explained_variance_score, mean_absolute_error, max_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "\n",
    "if CONFIG['BINARIZER'] == 'QUANTILE':\n",
    "    from aix360.algorithms.rbm import FeatureBinarizer\n",
    "elif CONFIG['BINARIZER'] == 'TREES':\n",
    "    from aix360.algorithms.rbm import FeatureBinarizerFromTrees\n",
    "if CONFIG['ALGO'] == 'RIPPER':\n",
    "    from aix360i.algorithms.rule_induction.ripper import Ripper\n",
    "elif CONFIG['ALGO'] == 'BRCG':\n",
    "    from aix360.algorithms.rbm import BooleanRuleCG # BRCGExplainer\n",
    "elif CONFIG['ALGO'] == 'CORELS':\n",
    "    from corels import *\n",
    "elif CONFIG['ALGO'] == 'Witt_RIPPER':\n",
    "    import wittgenstein as lw\n",
    "elif CONFIG['ALGO'] == 'GLRM':\n",
    "    from aix360.algorithms.rbm import GLRMExplainer, LinearRuleRegression\n",
    "\n",
    "# from explainer import Explainer\n",
    "\n",
    "# TODO create reference for performance using boosted trees\n",
    "\n",
    "# import wittgenstein as lw\n",
    "# from clf_utils import make_tree_dataset, make_forest, score_forest\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   creditScore          100000 non-null  float64\n",
      " 1   income               100000 non-null  float64\n",
      " 2   loanAmount           100000 non-null  float64\n",
      " 3   monthDuration        100000 non-null  float64\n",
      " 4   rate                 100000 non-null  float64\n",
      " 5   approval             100000 non-null  bool   \n",
      " 6   yearlyReimbursement  100000 non-null  float64\n",
      "dtypes: bool(1), float64(6)\n",
      "memory usage: 4.7 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True     78046\n",
       "False    21954\n",
       "Name: approval, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert(char):\n",
    "    if char == CONFIG['POS_CLASS']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df = pd.read_csv(CONFIG['DATA_SET'],dtype=CONFIG['DATA_TYPES'])\n",
    "df = df.drop(columns=CONFIG['DROP'])\n",
    "if CONFIG['ALGO'] == 'BRCG' or CONFIG['ALGO'] == 'CORELS' :\n",
    "    df[CONFIG['TARGET_LABEL']] = df[CONFIG['TARGET_LABEL']].map(convert)\n",
    "    CONFIG['POS_CLASS'] = 1\n",
    "    # maybe this could also be achieved through explicit binarization of target vector\n",
    "df.info()\n",
    "df[CONFIG['TARGET_LABEL']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot\n",
    "# Helper Function\n",
    "if CONFIG[\"ONEHOT\"] == True:\n",
    "    from collections import defaultdict\n",
    "    from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "    categorial_feat = df.select_dtypes(include=['object']).columns\n",
    "    numercial_feat = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "    def one_hot_encode_category(df, categorial_index):\n",
    "        d = defaultdict(LabelEncoder)\n",
    "        # Encoding\n",
    "        lecatdata = df[categorial_index].apply(lambda x: d[x.name].fit_transform(x))\n",
    "        for x in range(len(categorial_index)):\n",
    "            print(categorial_index[x],\": \", df[categorial_index[x]].unique())\n",
    "            print(categorial_index[x],\": \", lecatdata[categorial_index[x]].unique())\n",
    "        #One hot encoding with dummy variable\n",
    "        dummyvars = pd.get_dummies(df[categorial_index])\n",
    "\n",
    "        return dummyvars\n",
    "\n",
    "    dummyvars =one_hot_encode_category(df,categorial_feat )\n",
    "    df = pd.concat([df[numercial_feat], dummyvars], axis = 1)\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nunder_sampling_fraud = df[df[\"Class\"] == 1]\\nunder_size = under_sampling_fraud.size\\nunder_sampling_legit = (df[df[\"Class\"] == 0]).sample(n=10000, random_state = 42)\\ndf = pd.concat([under_sampling_legit, under_sampling_fraud])'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# undersampling for config 2\n",
    "''' \n",
    "under_sampling_fraud = df[df[\"Class\"] == 1]\n",
    "under_size = under_sampling_fraud.size\n",
    "under_sampling_legit = (df[df[\"Class\"] == 0]).sample(n=10000, random_state = 42)\n",
    "df = pd.concat([under_sampling_legit, under_sampling_fraud])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG['POS_CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     78046\n",
      "False    21954\n",
      "Name: approval, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if CONFIG['TYPE'] == 'BINARY':\n",
    "    print(df[CONFIG['TARGET_LABEL']].value_counts())\n",
    "elif CONFIG['TYPE'] == 'CONTINUOUS':\n",
    "    df[CONFIG['TARGET_LABEL']].describe()\n",
    "else:\n",
    "    print('Unrecognized problem type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (70000, 6) (70000,)\n",
      "Test: (30000, 6) (30000,)\n"
     ]
    }
   ],
   "source": [
    "if CONFIG['TRAIN_TEST_SPLIT'] == 'FIXED':\n",
    "    if CONFIG['MODE'] == 'PREDICTIVE':\n",
    "        train = df[df['is_test_set'] == False]\n",
    "        test = df[df['is_test_set'] == True]\n",
    "    elif CONFIG['MODE'] == 'DESCRIPTIVE':\n",
    "        train = df\n",
    "        test = df\n",
    "\n",
    "    train = train.drop(columns=['is_test_set'])\n",
    "    test = test.drop(columns=['is_test_set'])\n",
    "\n",
    "    y_train = train[CONFIG['TARGET_LABEL']]\n",
    "    x_train = train.drop(columns=[CONFIG['TARGET_LABEL']])\n",
    "\n",
    "    y_test = test[CONFIG['TARGET_LABEL']]\n",
    "    x_test = test.drop(columns=[CONFIG['TARGET_LABEL']])\n",
    "else:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df.drop(columns=[CONFIG['TARGET_LABEL']]), df[CONFIG['TARGET_LABEL']], test_size=CONFIG['TRAIN_TEST_SPLIT'], random_state=42)\n",
    "\n",
    "print('Training:', x_train.shape, y_train.shape)\n",
    "print('Test:', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG['TYPE'] == 'CONTINUOUS':\n",
    "    print('needs prior encoding of categoricals')\n",
    "    # gbr = GradientBoostingRegressor(n_estimators=500, random_state=0)\n",
    "    # gbr.fit(x_train, y_train)\n",
    "    # # print('Training R^2:', r2_score(yTrain, gbr.predict(dfTrain)))\n",
    "    # print('Test R^2:', r2_score(y_test, gbr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 70000 entries, 76513 to 15795\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   creditScore          70000 non-null  float64\n",
      " 1   income               70000 non-null  float64\n",
      " 2   loanAmount           70000 non-null  float64\n",
      " 3   monthDuration        70000 non-null  float64\n",
      " 4   rate                 70000 non-null  float64\n",
      " 5   yearlyReimbursement  70000 non-null  float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 3.7 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditScore</th>\n",
       "      <th>income</th>\n",
       "      <th>loanAmount</th>\n",
       "      <th>monthDuration</th>\n",
       "      <th>rate</th>\n",
       "      <th>yearlyReimbursement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76513</th>\n",
       "      <td>323.0</td>\n",
       "      <td>142660.0</td>\n",
       "      <td>1371289.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.057102</td>\n",
       "      <td>150327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60406</th>\n",
       "      <td>781.0</td>\n",
       "      <td>138610.0</td>\n",
       "      <td>88183.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.049289</td>\n",
       "      <td>6296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27322</th>\n",
       "      <td>458.0</td>\n",
       "      <td>190396.0</td>\n",
       "      <td>1073466.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.057622</td>\n",
       "      <td>120683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53699</th>\n",
       "      <td>569.0</td>\n",
       "      <td>36948.0</td>\n",
       "      <td>817845.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>0.050611</td>\n",
       "      <td>53114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65412</th>\n",
       "      <td>633.0</td>\n",
       "      <td>60520.0</td>\n",
       "      <td>1113649.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.037175</td>\n",
       "      <td>70057.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       creditScore    income  loanAmount  monthDuration      rate  \\\n",
       "76513        323.0  142660.0   1371289.0          155.0  0.057102   \n",
       "60406        781.0  138610.0     88183.0          286.0  0.049289   \n",
       "27322        458.0  190396.0   1073466.0          150.0  0.057622   \n",
       "53699        569.0   36948.0    817845.0          359.0  0.050611   \n",
       "65412        633.0   60520.0   1113649.0          289.0  0.037175   \n",
       "\n",
       "       yearlyReimbursement  \n",
       "76513             150327.0  \n",
       "60406               6296.0  \n",
       "27322             120683.0  \n",
       "53699              53114.0  \n",
       "65412              70057.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if CONFIG['BINARIZER'] == 'TREES':\n",
    "    binarizer =  FeatureBinarizerFromTrees(negations=False, randomState=42) # FeatureBinarizer(negations=False), FeatureBinarizerFromTrees(negations=True, randomState=42)\n",
    "    binarizer = binarizer.fit(x_train, y_train)\n",
    "    x_train_bin = binarizer.transform(x_train) #  x_train_bin = binarizer.fit_transform(x_train)\n",
    "    x_test_bin = binarizer.transform(x_test) #  X_fb = self.fb.fit_transform(X_train)\n",
    "elif CONFIG['BINARIZER'] == 'QUANTILE':\n",
    "    binarizer =  FeatureBinarizer(numThresh=9,negations=False, randomState=42) # FeatureBinarizer(negations=False), FeatureBinarizerFromTrees(negations=True, randomState=42)\n",
    "    binarizer = binarizer.fit(x_train)\n",
    "    x_train_bin = binarizer.transform(x_train) #  x_train_bin = binarizer.fit_transform(x_train)\n",
    "    x_test_bin = binarizer.transform(x_test) #  X_fb = self.fb.fit_transform(X_train)  \n",
    "elif CONFIG['BINARIZER'] == 'NATIVE':\n",
    "    x_train_bin = x_train\n",
    "    x_test_bin = x_test\n",
    "else:\n",
    "    print('UNRECOGNIZED BINARIZER')\n",
    "\n",
    "x_train_bin.info() # verbose=True\n",
    "x_train_bin.head()\n",
    "#x_train_bin[CONFIG['EXAMPLE_FEATURE']][:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule Induction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for RIPPER\n",
      "set to True\n",
      "Training time: 76.98400521278381\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print('Starting training for', CONFIG['ALGO'])\n",
    "\n",
    "if CONFIG['ALGO'] == 'BRCG':\n",
    "    estimator = BooleanRuleCG() # Explainer()\n",
    "    # estimator.train(x_train, y_train)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        estimator.fit(x_train_bin, y_train)\n",
    "elif CONFIG['ALGO'] == 'RIPPER':\n",
    "    estimator = Ripper()\n",
    "    estimator.fit(x_train_bin, y_train, pos_value=CONFIG['POS_CLASS'])\n",
    "elif CONFIG['ALGO'] == 'Witt_RIPPER':\n",
    "    estimator = lw.RIPPER()\n",
    "    estimator.fit(x_train_bin, y_train,class_feat=CONFIG[\"TARGET_LABEL\"] , pos_value=CONFIG['POS_CLASS'])\n",
    "elif CONFIG['ALGO'] == 'GLRM':\n",
    "    linear_model = LinearRuleRegression() # lambda0=0.0005,lambda1=0.0001\n",
    "    explainer = GLRMExplainer(linear_model)\n",
    "    explainer.fit(x_train_bin, y_train)\n",
    "elif CONFIG['ALGO'] == 'CORELS':\n",
    "    estimator = CorelsClassifier(n_iter=10000, \n",
    "                      # feautres per statement\n",
    "                     c = 0.0001 # Higher values penalise longer rulelists\n",
    "                    )\n",
    "    estimator.fit(x_train_bin, y_train , prediction_name = CONFIG[\"TARGET_LABEL\"])\n",
    "    \n",
    "else:\n",
    "    print('Unrecognized algorithm:', CONFIG['ALGO'])\n",
    "\n",
    "end_time = time.time()\n",
    "print('Training time: ' + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG['POS_CLASS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9954333333333333\n",
      "Balanced accuracy: 0.991695265503403\n",
      "Precision: 0.9939981532779316\n",
      "Recall: 0.9850541406130853\n",
      "F1 0.9895059364228265\n",
      "ConfusionMatrix [[ 6459    98]\n",
      " [   39 23404]]\n",
      "F-2 0.9868300433905763\n",
      "Mathhews 0.9866041622720696\n",
      "Stored 'acc_list' (list)\n",
      "Stored 'prec_list' (list)\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "prec_list = []\n",
    "%store -r acc_list\n",
    "%store -r prec_list\n",
    "\n",
    "if CONFIG['TYPE'] == 'BINARY':\n",
    "    y_pred = estimator.predict(x_test_bin)\n",
    "    print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print('Balanced accuracy:', balanced_accuracy_score(y_test, y_pred))\n",
    "    print('Precision:', precision_score(y_test, y_pred, pos_label=CONFIG['POS_CLASS']))\n",
    "    print('Recall:', recall_score(y_test, y_pred, pos_label=CONFIG['POS_CLASS']))\n",
    "    print('F1', f1_score(y_test, y_pred, pos_label=CONFIG['POS_CLASS']))\n",
    "    print('ConfusionMatrix', confusion_matrix(y_test, y_pred))\n",
    "    print('F-2', fbeta_score(y_test, y_pred, pos_label=CONFIG['POS_CLASS'], beta= 2))\n",
    "    print('Mathhews', matthews_corrcoef(y_test, y_pred))\n",
    "\n",
    "    acc_list.append(recall_score(y_test, y_pred, pos_label=CONFIG['POS_CLASS']))\n",
    "    prec_list.append(precision_score(y_test, y_pred, pos_label=CONFIG['POS_CLASS']))\n",
    "    %store acc_list\n",
    "    %store prec_list\n",
    "   \n",
    "elif CONFIG['TYPE'] == 'CONTINUOUS':\n",
    "    y_pred = explainer.predict(x_test_bin)\n",
    "    print(f'R2 Score = {r2_score(y_test, y_pred)}')\n",
    "    print(f'Explained Variance = {explained_variance_score(y_test, y_pred)}')\n",
    "    print(f'Mean abs. error = {mean_absolute_error(y_test, y_pred)}')\n",
    "    print(f'Max error = {max_error(y_test, y_pred)}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     23443\n",
       "False     6557\n",
       "Name: approval, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG['POS_CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NATIVE'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG['BINARIZER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RIPPER'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG['ALGO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     78046\n",
       "False    21954\n",
       "Name: approval, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[CONFIG[\"TARGET_LABEL\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hvo/opt/miniconda3/envs/aix360iripper2/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:47:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.9982\n",
      "Balanced accuracy: 0.997365266751356\n",
      "Precision: 0.9958822632301357\n",
      "Recall: 0.9958822632301357\n",
      "F-2 0.9958822632301357\n",
      "ConfusionMatrix [[ 6530    27]\n",
      " [   27 23416]]\n",
      "Mathhews 0.9947305335027118\n"
     ]
    }
   ],
   "source": [
    "#XGboost for Binary Classification\n",
    "\n",
    "    \n",
    "if CONFIG['TYPE'] == 'BINARY' and CONFIG['BASELINE'] == True:\n",
    "    \n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    x_train_bin.columns = [regex.sub(\"_\", str(col)) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_train_bin.columns.values]\n",
    "    x_test_bin.columns = [regex.sub(\"_\", str(col)) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_test_bin.columns.values]\n",
    "\n",
    "    xgb_cl = xgb.XGBClassifier()\n",
    "    xgb_cl.fit(x_train_bin, y_train)\n",
    "    preds = xgb_cl.predict(x_test_bin)     \n",
    "    print('Accuracy:', accuracy_score(y_test, preds))\n",
    "    print('Balanced accuracy:', balanced_accuracy_score(y_test, preds))\n",
    "    print('Precision:', precision_score(y_test, preds, pos_label=CONFIG['POS_CLASS']))\n",
    "    print('Recall:', recall_score(y_test, preds, pos_label=CONFIG['POS_CLASS']))\n",
    "    print('F-2', fbeta_score(y_test, preds, pos_label=CONFIG['POS_CLASS'], beta= 2))\n",
    "    print('ConfusionMatrix', confusion_matrix(y_test, preds))\n",
    "    print('Mathhews', matthews_corrcoef(y_test, preds))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG['POS_CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule count: 30\n",
      "Rule set:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-93cac40a451c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#print(estimator.rule_list_to_pretty_string())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Get predicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrule_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrule_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mpräds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrule_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "präds = []\n",
    "if CONFIG['TYPE'] == 'CONTINUOUS':\n",
    "    explanation = explainer.explain()\n",
    "    print(explanation)\n",
    "elif CONFIG['ALGO'] == 'BRCG':\n",
    "    model = estimator.explain()\n",
    "    if not model['isCNF']:\n",
    "        print('Number of rules:', len(model['rules']))\n",
    "        print(model['rules'])\n",
    "elif CONFIG['ALGO'] == 'RIPPER':\n",
    "    \n",
    "    print('Rule count: ' + str(sum([len(rules) for rules in estimator.rule_map.values()])))\n",
    "    print('Rule set:')\n",
    "    #print(estimator.rule_list_to_pretty_string())\n",
    "    # Get predicates\n",
    "    for i in range(len(estimator.rule_map[1])):\n",
    "        print(len(estimator.rule_map[1][i]))\n",
    "        präds.append(len(estimator.rule_map[1][i]))\n",
    "    print(\"Sum Prädikate:\", sum(präds))\n",
    "elif CONFIG['ALGO'] == 'CORELS':\n",
    "    r_length = len(estimator.rl().rules)\n",
    "    print(\"Rule Length:\", r_length)\n",
    "    # Get predicates\n",
    "    for i in range(len(estimator.rl().rules[0][\"antecedents\"])):\n",
    "        an = len(estimator.rl().rules[i][\"antecedents\"])\n",
    "        präds.append(len(estimator.rl().rules[i][\"antecedents\"]))\n",
    "        print(f\"Antecedents Length Rule {i}:\" , an)\n",
    "    print(\"Sum Prädikate:\", sum(präds))\n",
    "elif CONFIG['ALGO'] == 'Witt_RIPPER':\n",
    "    print(\"Rule Length:\", len(estimator.ruleset_))\n",
    "\n",
    "# uncomment the following line for a full optimized view of the model as data frame for GLRM rules\n",
    "# explanation.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(estimator.rule_map[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
